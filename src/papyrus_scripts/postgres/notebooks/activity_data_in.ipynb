{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "376b9205",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T14:59:40.841958Z",
     "start_time": "2022-05-30T14:59:40.328162Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/code')\n",
    "\n",
    "from database.models import (Protein, Organism, Classification, Molecule, Activity, ActivityType, Source, Quality, CID)\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import scoped_session\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import os\n",
    "import glob\n",
    "from rdkit import Chem\n",
    "from razi.rdkit_postgresql.functions import morganbv_fp\n",
    "\n",
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import multiprocessing\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from copy import copy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_db_session():\n",
    "    engine = create_engine(\n",
    "        'postgresql://postgres:postgres@papyrusdb/papyrus', convert_unicode=True,\n",
    "        pool_recycle=3600, pool_size=10)\n",
    "    db_session = scoped_session(sessionmaker(\n",
    "        autocommit=False, autoflush=False, bind=engine))\n",
    "    \n",
    "    return db_session\n",
    "\n",
    "\n",
    "def get_or_create(session, model, **kwargs):\n",
    "    instance = session.query(model).filter_by(**kwargs).first()\n",
    "    if instance:\n",
    "#         created = False\n",
    "        return instance\n",
    "    else:\n",
    "#         created = True\n",
    "        instance = model(**kwargs)\n",
    "        session.add(instance)\n",
    "        session.commit()\n",
    "        session.flush()\n",
    "        session.refresh(instance)\n",
    "        return instance\n",
    "    \n",
    "def get_or_instance(session, model, **kwargs):\n",
    "    instance = session.query(model).filter_by(**kwargs).first()\n",
    "    if instance:\n",
    "        return instance\n",
    "    else:\n",
    "        instance = model(**kwargs)\n",
    "        return instance\n",
    "    \n",
    "def sanitize_and_split(row, keyval, length, spl=';'):\n",
    "    split = [v.rstrip() for v in str(row[keyval]).split(spl)]\n",
    "    if len(split)!= length:\n",
    "        split = [split[0] for i in range(0,length)]\n",
    "    \n",
    "    split = [None if x == '' else x for x in split]\n",
    "    \n",
    "    return split\n",
    "\n",
    "def sanitize_and_split(row, length, spl=';'):\n",
    "    split = [v.rstrip() for v in str(row).split(spl)]\n",
    "    if len(split)!= length:\n",
    "        split = [split[0] for i in range(0,length)]\n",
    "    \n",
    "    split = [None if x == '' else x for x in split]\n",
    "    \n",
    "    return split\n",
    "\n",
    "\n",
    "class TypeDecoder(json.JSONDecoder):\n",
    "    \"\"\"Custom json decoder to support types as values.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"Simple json decoder handling types as values.\"\"\"\n",
    "        json.JSONDecoder.__init__(self, object_hook=self.object_hook, *args, **kwargs)\n",
    "\n",
    "    def object_hook(self, obj):\n",
    "        \"\"\"Handle types.\"\"\"\n",
    "        if '__type__' not in obj:\n",
    "            return obj\n",
    "        module = obj['__type__']['module']\n",
    "        type_ = obj['__type__']['type']\n",
    "        if module == 'builtins':\n",
    "            return getattr(__builtins__, type_)\n",
    "        loaded_module = importlib.import_module(module)\n",
    "        return getattr(loaded_module, type_)\n",
    "    \n",
    "\n",
    "\n",
    "dtype_file = '../.data/papyrus/05.5/data_types.json'\n",
    "activity_data = '../.data/papyrus/05.5/05.5_combined_set_without_stereochemistry.tsv.xz'\n",
    "protein_data = '../.data/papyrus/05.5/05.5_combined_set_protein_targets.tsv.xz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de77a85c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T14:59:40.855644Z",
     "start_time": "2022-05-30T14:59:40.844979Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(dtype_file, 'r') as jsonfile:\n",
    "        dtypes = json.load(jsonfile, cls=TypeDecoder)['papyrus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b7969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T15:29:44.722093Z",
     "start_time": "2022-05-26T15:29:44.569082Z"
    }
   },
   "outputs": [],
   "source": [
    "protein_df = pd.read_csv(protein_data, sep='\\t', dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2d3070",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T15:29:45.571112Z",
     "start_time": "2022-05-26T15:29:45.561539Z"
    }
   },
   "outputs": [],
   "source": [
    "organisms = list(set(protein_df['Organism']))\n",
    "classifications = []\n",
    "for cstr in protein_df['Classification']:\n",
    "    classifications.extend(str(cstr).split('->'))\n",
    "\n",
    "classes = list(set(classifications))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303809f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T15:30:03.792239Z",
     "start_time": "2022-05-26T15:29:46.732740Z"
    }
   },
   "outputs": [],
   "source": [
    "db_session = get_db_session()\n",
    "\n",
    "rows = []\n",
    "\n",
    "for i, row in protein_df.iterrows():\n",
    "    organism = get_or_create(session=db_session, model=Organism, organism=row['Organism'])\n",
    "    classifications_list = str(row['Classification']).split('->')\n",
    "    classifications = [get_or_create(session=db_session, model=Classification, classification=c) for c in classifications_list]\n",
    "    \n",
    "    review_mapping = {'reviewed':1, 'Unreviewed':0, 'unreviewed':0}\n",
    "    \n",
    "    prot = Protein(\n",
    "        target_id = row['target_id'],\n",
    "        HGNC_symbol = str(row['HGNC_symbol']),\n",
    "        uniprot_id = row['UniProtID'],\n",
    "        reviewed = review_mapping[row['Status']],\n",
    "        organism = organism.id,\n",
    "        length = row['Length'],\n",
    "        sequence = row['Sequence'], \n",
    "        classifications = classifications\n",
    "    )\n",
    "    \n",
    "    rows.append(prot)\n",
    "    \n",
    "db_session.add_all(rows)\n",
    "db_session.commit()\n",
    "db_session.remove()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9ca3087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T14:59:43.893584Z",
     "start_time": "2022-05-30T14:59:43.877084Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_activity_frame(df):\n",
    "#     df_obj = df.select_dtypes(['object'])\n",
    "    db_session = get_db_session()\n",
    "    rows = []\n",
    "    \n",
    "    activity_type_map = {\n",
    "        '1000':'IC50',\n",
    "        '0100':'EC50',\n",
    "        '0010':'KD',\n",
    "        '0001':'Ki',\n",
    "        '0000':'other',\n",
    "    }\n",
    "\n",
    "    print('processing frame')\n",
    "    \n",
    "    # do this bit in parallel?\n",
    "    for row in tqdm(df.itertuples()):\n",
    "        sources_list = row.source.split(';')\n",
    "        cids_list = row.CID.split(';')\n",
    "        sources_cids_list = list(zip(sources_list, cids_list))\n",
    "        cids = [      \n",
    "            get_or_create(session=db_session, \n",
    "                          model=CID, \n",
    "                          cid=c[1], \n",
    "                          source=get_or_create(session=db_session, \n",
    "                                               model=Source, \n",
    "                                               source=c[0]).source) for c in sources_cids_list]\n",
    "\n",
    "        mol = Chem.MolFromSmiles(row.SMILES)\n",
    "        fp = morganbv_fp(row.SMILES)\n",
    "\n",
    "        # change this to use InChI and/or SMILES\n",
    "        smiles = Chem.CanonSmiles(row.SMILES)\n",
    "        molecule = get_or_instance(session=db_session,model=Molecule,smiles=smiles,inchi=row.InChI)\n",
    "#         molecule = get_or_instance(session=db_session,model=Molecule,mol=mol)\n",
    "        \n",
    "        if molecule.cids != cids:\n",
    "            molecule.cids=cids\n",
    "            molecule.smiles=smiles\n",
    "            molecule.mol=mol\n",
    "#             molecule.smiles=row.SMILES\n",
    "            molecule.inchi_key=row.InChIKey\n",
    "            molecule.inchi=row.InChI\n",
    "            molecule.inchi_auxinfo=row.InChI_AuxInfo\n",
    "            molecule.fp=fp\n",
    "            molecule.connectivity=row.connectivity\n",
    "            db_session.add(molecule)\n",
    "            db_session.commit()\n",
    "            db_session.flush()\n",
    "            db_session.refresh(molecule)\n",
    "\n",
    "        quality = get_or_create(session=db_session, model=Quality, quality=row.Quality).id\n",
    "        target_id = get_or_create(session=db_session, model=Protein, target_id=row.target_id).target_id\n",
    "        molecule_id = molecule.id\n",
    "\n",
    "        slice_list = []\n",
    "        if ';' in str(row.pchembl_value):\n",
    "\n",
    "            pchembl_values = [v.rstrip() for v in row.pchembl_value.split(';')]\n",
    "            length = len(pchembl_values)\n",
    "\n",
    "            aids = sanitize_and_split(row=row.AID,length=length)        \n",
    "            doc_ids = sanitize_and_split(row=row.all_doc_ids,length=length)\n",
    "            years = sanitize_and_split(row=row.all_years,length=length)\n",
    "            type_IC50s = sanitize_and_split(row=row.type_IC50,length=length)         \n",
    "            type_EC50s = sanitize_and_split(row=row.type_EC50,length=length)\n",
    "            type_KDs = sanitize_and_split(row=row.type_KD,length=length)\n",
    "            type_Kis = sanitize_and_split(row=row.type_Ki,length=length)\n",
    "\n",
    "            for j in range(0, len(pchembl_values)):\n",
    "                update_dict = {\n",
    "                    'pchembl_value': pchembl_values[j],\n",
    "                    'AID': aids[j],\n",
    "                    'doc_id': doc_ids[j],\n",
    "                    'Year': years[j],\n",
    "                    'type_IC50': type_IC50s[j],\n",
    "                    'type_EC50': type_EC50s[j],\n",
    "                    'type_KD': type_KDs[j],\n",
    "                    'type_Ki': type_Kis[j]\n",
    "                }\n",
    "                row_copy = copy(row._asdict())\n",
    "\n",
    "                row_copy.update(update_dict)\n",
    "\n",
    "                slice_list.append(row_copy)\n",
    "\n",
    "        else:\n",
    "            slice_list.append(row._asdict())\n",
    "\n",
    "        for s in slice_list:\n",
    "\n",
    "            a = f\"{s['type_IC50']}{s['type_EC50']}{s['type_KD']}{s['type_Ki']}\"\n",
    "            activity_type_str = activity_type_map[a]\n",
    "\n",
    "            activity_type = get_or_create(session=db_session, model=ActivityType, type=activity_type_str).id\n",
    "\n",
    "            try:\n",
    "                y = int(s['Year'])\n",
    "            except:\n",
    "                y = None\n",
    "\n",
    "            activity = Activity(\n",
    "                papyrus_activity_id=s['Activity_ID'],\n",
    "                quality=quality,\n",
    "                target_id=target_id,\n",
    "                molecule_id = molecule_id,\n",
    "                accession=s['accession'],\n",
    "                protein_type=s['Protein_Type'],\n",
    "                aid = s['AID'],\n",
    "                doc_id = s['doc_id'],\n",
    "                year = y,\n",
    "                type = activity_type, \n",
    "                relation = s['relation'],\n",
    "                pchembl_value = s['pchembl_value'],\n",
    "                pchembl_value_mean = s['pchembl_value_Mean'],\n",
    "                pchembl_value_stdev = s['pchembl_value_StdDev'],\n",
    "                pchembl_value_SEM = s['pchembl_value_SEM'],\n",
    "                pchembl_value_n = s['pchembl_value_N'],\n",
    "                pchembl_value_median = s['pchembl_value_Median'],\n",
    "                pchembl_value_mad = s['pchembl_value_MAD'],   \n",
    "            )\n",
    "\n",
    "            rows.append(activity)\n",
    "            \n",
    "    print('processing complete')\n",
    "            \n",
    "    del(df)\n",
    "    db_session.add_all(rows)\n",
    "    print('committing activities')\n",
    "    db_session.commit()\n",
    "    db_session.close()\n",
    "    db_session.remove()\n",
    "    gc.collect()\n",
    "            \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738fc5a6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-30T14:59:37.597Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4386/1129091749.py:27: SADeprecationWarning: The create_engine.convert_unicode parameter and corresponding dialect-level parameters are deprecated, and will be removed in a future release.  Modern DBAPIs support Python Unicode natively and this parameter is unnecessary.\n",
      "  engine = create_engine(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Protein.classification' will copy column protein.target_id to column ProteinClassification.protein_id, which conflicts with relationship(s): 'Classification.protein' (copies protein.target_id to ProteinClassification.protein_id), 'Protein.classifications' (copies protein.target_id to ProteinClassification.protein_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Protein.classification' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Protein.classification' will copy column classification.id to column ProteinClassification.classification_id, which conflicts with relationship(s): 'Classification.protein' (copies classification.id to ProteinClassification.classification_id), 'Protein.classifications' (copies classification.id to ProteinClassification.classification_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Protein.classification' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Classification.proteins' will copy column classification.id to column ProteinClassification.classification_id, which conflicts with relationship(s): 'Classification.protein' (copies classification.id to ProteinClassification.classification_id), 'Protein.classifications' (copies classification.id to ProteinClassification.classification_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Classification.proteins' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Classification.proteins' will copy column protein.target_id to column ProteinClassification.protein_id, which conflicts with relationship(s): 'Classification.protein' (copies protein.target_id to ProteinClassification.protein_id), 'Protein.classifications' (copies protein.target_id to ProteinClassification.protein_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Classification.proteins' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "5it [00:00, 43.71it/s]/tmp/ipykernel_4386/1129091749.py:27: SADeprecationWarning: The create_engine.convert_unicode parameter and corresponding dialect-level parameters are deprecated, and will be removed in a future release.  Modern DBAPIs support Python Unicode natively and this parameter is unnecessary.\n",
      "  engine = create_engine(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Protein.classification' will copy column protein.target_id to column ProteinClassification.protein_id, which conflicts with relationship(s): 'Classification.protein' (copies protein.target_id to ProteinClassification.protein_id), 'Protein.classifications' (copies protein.target_id to ProteinClassification.protein_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Protein.classification' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Protein.classification' will copy column classification.id to column ProteinClassification.classification_id, which conflicts with relationship(s): 'Classification.protein' (copies classification.id to ProteinClassification.classification_id), 'Protein.classifications' (copies classification.id to ProteinClassification.classification_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Protein.classification' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Classification.proteins' will copy column classification.id to column ProteinClassification.classification_id, which conflicts with relationship(s): 'Classification.protein' (copies classification.id to ProteinClassification.classification_id), 'Protein.classifications' (copies classification.id to ProteinClassification.classification_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Classification.proteins' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Classification.proteins' will copy column protein.target_id to column ProteinClassification.protein_id, which conflicts with relationship(s): 'Classification.protein' (copies protein.target_id to ProteinClassification.protein_id), 'Protein.classifications' (copies protein.target_id to ProteinClassification.protein_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Classification.proteins' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "23it [00:00, 76.62it/s]/tmp/ipykernel_4386/1129091749.py:27: SADeprecationWarning: The create_engine.convert_unicode parameter and corresponding dialect-level parameters are deprecated, and will be removed in a future release.  Modern DBAPIs support Python Unicode natively and this parameter is unnecessary.\n",
      "  engine = create_engine(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Protein.classification' will copy column protein.target_id to column ProteinClassification.protein_id, which conflicts with relationship(s): 'Classification.protein' (copies protein.target_id to ProteinClassification.protein_id), 'Protein.classifications' (copies protein.target_id to ProteinClassification.protein_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Protein.classification' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Protein.classification' will copy column classification.id to column ProteinClassification.classification_id, which conflicts with relationship(s): 'Classification.protein' (copies classification.id to ProteinClassification.classification_id), 'Protein.classifications' (copies classification.id to ProteinClassification.classification_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Protein.classification' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Classification.proteins' will copy column classification.id to column ProteinClassification.classification_id, which conflicts with relationship(s): 'Classification.protein' (copies classification.id to ProteinClassification.classification_id), 'Protein.classifications' (copies classification.id to ProteinClassification.classification_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Classification.proteins' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Classification.proteins' will copy column protein.target_id to column ProteinClassification.protein_id, which conflicts with relationship(s): 'Classification.protein' (copies protein.target_id to ProteinClassification.protein_id), 'Protein.classifications' (copies protein.target_id to ProteinClassification.protein_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Classification.proteins' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "44it [00:00, 157.74it/s]/tmp/ipykernel_4386/1129091749.py:27: SADeprecationWarning: The create_engine.convert_unicode parameter and corresponding dialect-level parameters are deprecated, and will be removed in a future release.  Modern DBAPIs support Python Unicode natively and this parameter is unnecessary.\n",
      "  engine = create_engine(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Protein.classification' will copy column protein.target_id to column ProteinClassification.protein_id, which conflicts with relationship(s): 'Classification.protein' (copies protein.target_id to ProteinClassification.protein_id), 'Protein.classifications' (copies protein.target_id to ProteinClassification.protein_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Protein.classification' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "39it [00:00, 70.63it/s]/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Protein.classification' will copy column classification.id to column ProteinClassification.classification_id, which conflicts with relationship(s): 'Classification.protein' (copies classification.id to ProteinClassification.classification_id), 'Protein.classifications' (copies classification.id to ProteinClassification.classification_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Protein.classification' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "12it [00:00, 58.73it/s]/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Classification.proteins' will copy column classification.id to column ProteinClassification.classification_id, which conflicts with relationship(s): 'Classification.protein' (copies classification.id to ProteinClassification.classification_id), 'Protein.classifications' (copies classification.id to ProteinClassification.classification_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Classification.proteins' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Classification.proteins' will copy column protein.target_id to column ProteinClassification.protein_id, which conflicts with relationship(s): 'Classification.protein' (copies protein.target_id to ProteinClassification.protein_id), 'Protein.classifications' (copies protein.target_id to ProteinClassification.protein_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Classification.proteins' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "22it [00:00, 76.19it/s]]/tmp/ipykernel_4386/1129091749.py:27: SADeprecationWarning: The create_engine.convert_unicode parameter and corresponding dialect-level parameters are deprecated, and will be removed in a future release.  Modern DBAPIs support Python Unicode natively and this parameter is unnecessary.\n",
      "  engine = create_engine(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Protein.classification' will copy column protein.target_id to column ProteinClassification.protein_id, which conflicts with relationship(s): 'Classification.protein' (copies protein.target_id to ProteinClassification.protein_id), 'Protein.classifications' (copies protein.target_id to ProteinClassification.protein_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Protein.classification' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Protein.classification' will copy column classification.id to column ProteinClassification.classification_id, which conflicts with relationship(s): 'Classification.protein' (copies classification.id to ProteinClassification.classification_id), 'Protein.classifications' (copies classification.id to ProteinClassification.classification_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Protein.classification' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "15it [00:00, 77.02it/s]/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Classification.proteins' will copy column classification.id to column ProteinClassification.classification_id, which conflicts with relationship(s): 'Classification.protein' (copies classification.id to ProteinClassification.classification_id), 'Protein.classifications' (copies classification.id to ProteinClassification.classification_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Classification.proteins' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "/tmp/ipykernel_4386/1129091749.py:37: SAWarning: relationship 'Classification.proteins' will copy column protein.target_id to column ProteinClassification.protein_id, which conflicts with relationship(s): 'Classification.protein' (copies protein.target_id to ProteinClassification.protein_id), 'Protein.classifications' (copies protein.target_id to ProteinClassification.protein_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"classifications,protein\"' to the 'Classification.proteins' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)\n",
      "  instance = session.query(model).filter_by(**kwargs).first()\n",
      "10000it [02:52, 57.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9705it [02:52, 53.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "committing activities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9824it [02:55, 39.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [02:57, 56.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9656it [02:57, 38.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "committing activities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "117it [00:02, 50.46it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [02:57, 56.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:02, 46.91it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "committing activities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [02:59, 55.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9740it [02:59, 28.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "committing activities"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "159it [00:03, 27.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:05, 17.71it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [00:09, 35.29it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [03:08, 53.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "94it [00:07,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "committing activities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "307it [00:28,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:02, 33.30it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4259it [03:39, 37.33it/s]"
     ]
    }
   ],
   "source": [
    "reader = pd.read_csv(activity_data, sep='\\t', compression='xz', chunksize = 10000, iterator=True, dtype=dtypes)\n",
    "\n",
    "# out_dir = '/tmp'\n",
    "# if not os.path.isdir(out_dir):\n",
    "#     os.mkdir(out_dir)\n",
    "\n",
    "# print('writing files')\n",
    "# count = 0\n",
    "# # for df in reader:\n",
    "# #     df.to_csv(f'{out_dir}/activity-chunk_{str(count)}.csv', index=False)\n",
    "# #     count += 1\n",
    "    \n",
    "# cores = 5    \n",
    "# chunked = glob.glob(f'{out_dir}/*.csv')\n",
    "\n",
    "# option 1: run each chunked file of 10000 rows separatley\n",
    "# for fn in chunked:\n",
    "#     df = pd.read_csv(fn, sep='\\t')\n",
    "#     process_activity_frame(df)\n",
    "    \n",
    "# def run(fn):\n",
    "#     reader = pd.read_csv(fn, chunksize = 10000, iterator=True, dtype=dtypes)\n",
    "#     for df in reader:\n",
    "#         process_activity_frame(df)\n",
    "    \n",
    "# # option 2: run files in parallel\n",
    "# print('running inserts')\n",
    "# with multiprocessing.Pool(processes=cores) as p:\n",
    "#         with tqdm(total=len(chunked)) as pbar:\n",
    "#             for _ in p.imap_unordered(run, [fn for fn in chunked]):\n",
    "#                 pbar.update()\n",
    "\n",
    "pool = multiprocessing.Pool(5) # use 4 processes\n",
    "\n",
    "for df in reader:\n",
    "    # process each data frame\n",
    "    pool.apply_async(process_activity_frame,[df])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6208dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a240a9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
